{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding is simply converting each value in a column to a number (0 to num_classes).\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car (toy) dataset \n",
    "https://archive.ics.uci.edu/ml/datasets/Car+Evaluation\n",
    "wget https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5      6\n",
       "0  vhigh  vhigh  2  2  small   low  unacc\n",
       "1  vhigh  vhigh  2  2  small   med  unacc\n",
       "2  vhigh  vhigh  2  2  small  high  unacc\n",
       "3  vhigh  vhigh  2  2    med   low  unacc\n",
       "4  vhigh  vhigh  2  2    med   med  unacc"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"car.data\", header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unacc', 'unacc', 'unacc', ..., 'unacc', 'good', 'vgood'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data.iloc[:, 6].values\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2, 3, 4, 5, 6], dtype='int64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([6], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5\n",
       "0  vhigh  vhigh  2  2  small   low\n",
       "1  vhigh  vhigh  2  2  small   med\n",
       "2  vhigh  vhigh  2  2  small  high\n",
       "3  vhigh  vhigh  2  2    med   low\n",
       "4  vhigh  vhigh  2  2    med   med"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2     3      4     5\n",
       "1223    med    low      3     2    big  high\n",
       "1517    low    med      2     2    med  high\n",
       "126   vhigh   high      2  more  small   low\n",
       "1715    low    low  5more     4    med  high\n",
       "58    vhigh  vhigh      4     2    med   med"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.20, random_state=3)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    object\n",
       "1    object\n",
       "2    object\n",
       "3    object\n",
       "4    object\n",
       "5    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_val.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    if X_train.dtypes[col] == \"object\":\n",
    "        le = LabelEncoder()\n",
    "        X_train[col] = le.fit_transform(X_train[col])\n",
    "        X_val[col] = le.transform(X_val[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 1, 2, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5\n",
       "0  2  1  1  0  0  0\n",
       "1  1  2  0  0  1  0\n",
       "2  3  0  0  2  2  1\n",
       "3  1  1  3  1  1  0\n",
       "4  3  3  2  0  1  2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5\n",
       "0  3  1  0  2  0  0\n",
       "1  3  0  0  0  1  2\n",
       "2  2  0  1  1  1  1\n",
       "3  0  2  2  1  1  2\n",
       "4  2  1  3  1  2  0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1382, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2, 3]),\n",
       " array([0, 1, 2, 3]),\n",
       " array([0, 1, 2, 3]),\n",
       " array([0, 1, 2]),\n",
       " array([0, 1, 2]),\n",
       " array([0, 1, 2])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.unique(X_train[col].values) for col in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 4, 3, 3, 3]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_levels = [len(np.unique(X_train[col].values)) for col in X_train]\n",
    "cat_levels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding layer\n",
    "Most deep learning models use a dense vectors of real numbers as representation of words or categorical variables, as opposed to a one-hot encoding representations. The module torch.nn.Embedding is used to represent word embeddings. It takes two arguments: number of levels in your categorical variable, and the dimensionality of the embeddings. The embeddings are initialized with random vectors and are learned in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.4497,  0.1786, -1.1235, -1.5645, -1.5388],\n",
       "        [ 2.0144, -1.5969, -0.5350, -0.6747, -0.2926],\n",
       "        [-1.5135, -0.4365, -0.6584, -0.1974, -0.0570],\n",
       "        [-0.2185,  0.0166, -0.5123, -0.9503, -0.0153]], requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An Embedding layer containing 4 categories and embedding size 5. \n",
    "# Embeddings will be initialized at random.\n",
    "embed = nn.Embedding(4, 5)\n",
    "embed.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0144, -1.5969, -0.5350, -0.6747, -0.2926],\n",
       "        [-1.4497,  0.1786, -1.1235, -1.5645, -1.5388],\n",
       "        [ 2.0144, -1.5969, -0.5350, -0.6747, -0.2926],\n",
       "        [-0.2185,  0.0166, -0.5123, -0.9503, -0.0153],\n",
       "        [-0.2185,  0.0166, -0.5123, -0.9503, -0.0153],\n",
       "        [-1.5135, -0.4365, -0.6584, -0.1974, -0.0570]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each categotical variable with K levels should be relabel with levels between 0 and K-1.\n",
    "# Given a coulmn x, to \"look up\" the embedding of each level do:\n",
    "# Note that it needs type LongTensor\n",
    "x = torch.LongTensor([1, 0, 1, 3, 3 , 2])\n",
    "embed(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, cat_levels, emb_size=5, n_class=4):\n",
    "        super().__init__()\n",
    "        self.embs = nn.ModuleList([nn.Embedding(c, emb_size) for c in cat_levels])\n",
    "        self.lin1 = nn.Linear(6*emb_size, 20)\n",
    "        self.lin2 = nn.Linear(20, n_class)\n",
    "        self.bn = nn.BatchNorm1d(20)\n",
    "        self.emb_drop = nn.Dropout(0.1)\n",
    "        self.drops = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # try to write a shorter code\n",
    "        e0 = self.embs[0](x[:,0])\n",
    "        e1 = self.embs[1](x[:,1])\n",
    "        e2 = self.embs[2](x[:,2])\n",
    "        e3 = self.embs[3](x[:,3])\n",
    "        e4 = self.embs[4](x[:,4])\n",
    "        e5 = self.embs[5](x[:,5])\n",
    "        x = torch.cat([e0, e1, e2, e3, e4, e5], 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabularModel(cat_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.0):\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.LongTensor(X_train.values)\n",
    "y_train = torch.LongTensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optim, epochs=5):\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        out = model(x_train)\n",
    "        loss = F.cross_entropy(out, y_train)   \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        val_loss, val_acc = val_metric(model)\n",
    "        if i % 15 == 0: \n",
    "            print(\"train loss %.3f val loss %.3f and accuracy %.3f\" % \n",
    "                  (loss, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = torch.LongTensor(X_val.values)\n",
    "y_val = torch.LongTensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metric(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    out = model(x_val)\n",
    "    loss = F.cross_entropy(out, y_val)\n",
    "    pred = torch.max(out, 1)[1]\n",
    "    correct += (pred == y_val).float().sum().item()\n",
    "    return loss, correct/y_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabularModel(cat_levels)\n",
    "optim = get_optimizer(model, lr = 0.01, wd = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.448 val loss 1.361 and accuracy 0.332\n",
      "train loss 0.602 val loss 0.573 and accuracy 0.792\n",
      "train loss 0.333 val loss 0.273 and accuracy 0.896\n",
      "train loss 0.221 val loss 0.173 and accuracy 0.951\n",
      "train loss 0.174 val loss 0.139 and accuracy 0.962\n",
      "train loss 0.145 val loss 0.112 and accuracy 0.974\n",
      "train loss 0.142 val loss 0.101 and accuracy 0.968\n",
      "train loss 0.115 val loss 0.081 and accuracy 0.986\n",
      "train loss 0.129 val loss 0.087 and accuracy 0.971\n",
      "train loss 0.109 val loss 0.079 and accuracy 0.968\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optim, epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WiDS 2018  dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this part of the notebook comes from this kaggle [competition](https://www.kaggle.com/c/wids2018datathon/). You are given a dataset of survey questions and results from a developing country. Your goal is to predict the gender of the respondent based on the other answers he/she provided. You Kaggle api to get the data. All variables in this dataset and categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install kaggle` <br/>\n",
    "\n",
    "`kaggle competitions download -c wids2018datathon -p /path/to/data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA5</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>...</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN1_OTHERS</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN2_OTHERS</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN3_OTHERS</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN4_OTHERS</th>\n",
       "      <th>GN5</th>\n",
       "      <th>GN5_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  AA3  AA4  AA5  AA6     AA7  AA14  AA15   DG1  is_female  ...  \\\n",
       "0         0    3   32  3.0  NaN  323011  3854   481  1975          1  ...   \n",
       "1         1    2   26  NaN  8.0  268131  2441   344  1981          1  ...   \n",
       "2         2    1   16  NaN  7.0  167581   754   143  1995          1  ...   \n",
       "3         3    4   44  5.0  NaN  445071  5705   604  1980          1  ...   \n",
       "4         4    4   43  NaN  6.0  436161  5645   592  1958          1  ...   \n",
       "\n",
       "    GN1  GN1_OTHERS GN2  GN2_OTHERS  GN3  GN3_OTHERS  GN4  GN4_OTHERS  GN5  \\\n",
       "0  99.0         NaN  99         NaN   99         NaN   99         NaN   99   \n",
       "1   NaN         NaN   1         NaN    2         NaN    2         NaN    2   \n",
       "2   1.0         NaN   2         NaN    2         NaN    2         NaN    2   \n",
       "3   NaN         NaN   2         NaN    2         NaN   99         NaN   99   \n",
       "4   NaN         NaN   1         NaN    1         NaN    1         NaN    1   \n",
       "\n",
       "   GN5_OTHERS  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 1235 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\", low_memory=False)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18255, 1235)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA5</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>DG3</th>\n",
       "      <th>...</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN1_OTHERS</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN2_OTHERS</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN3_OTHERS</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN4_OTHERS</th>\n",
       "      <th>GN5</th>\n",
       "      <th>GN5_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA5  AA6     AA7  AA14  AA15   DG1  is_female  DG3  ...   GN1  \\\n",
       "0    3   32  3.0  NaN  323011  3854   481  1975          1    3  ...  99.0   \n",
       "1    2   26  NaN  8.0  268131  2441   344  1981          1    8  ...   NaN   \n",
       "2    1   16  NaN  7.0  167581   754   143  1995          1    3  ...   1.0   \n",
       "3    4   44  5.0  NaN  445071  5705   604  1980          1    3  ...   NaN   \n",
       "4    4   43  NaN  6.0  436161  5645   592  1958          1    3  ...   NaN   \n",
       "\n",
       "  GN1_OTHERS  GN2  GN2_OTHERS  GN3  GN3_OTHERS  GN4  GN4_OTHERS  GN5  \\\n",
       "0        NaN   99         NaN   99         NaN   99         NaN   99   \n",
       "1        NaN    1         NaN    2         NaN    2         NaN    2   \n",
       "2        NaN    2         NaN    2         NaN    2         NaN    2   \n",
       "3        NaN    2         NaN    2         NaN   99         NaN   99   \n",
       "4        NaN    1         NaN    1         NaN    1         NaN    1   \n",
       "\n",
       "   GN5_OTHERS  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 1234 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train id looks like a unique id for each row\n",
    "train = train.drop(columns=[\"train_id\"])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning columns with too many NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12602"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"AA5\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AA3               0\n",
       "AA4               0\n",
       "AA5           12602\n",
       "AA6            5653\n",
       "AA7               0\n",
       "              ...  \n",
       "GN3_OTHERS    18172\n",
       "GN4               0\n",
       "GN4_OTHERS    18169\n",
       "GN5               0\n",
       "GN5_OTHERS    18179\n",
       "Length: 1234, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the number of NULL in per column\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropping columns with too many nulls\n",
    "for col in train.columns:\n",
    "    if train[col].isnull().sum() > 12000:\n",
    "        train.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>...</th>\n",
       "      <th>LN2_2</th>\n",
       "      <th>LN2_3</th>\n",
       "      <th>LN2_4</th>\n",
       "      <th>LN2_RIndLngBEOth</th>\n",
       "      <th>LN2_WIndLngBEOth</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 421 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA6     AA7  AA14  AA15   DG1  is_female  DG3  DG3A  ...  LN2_2  \\\n",
       "0    3   32  NaN  323011  3854   481  1975          1    3     4  ...      1   \n",
       "1    2   26  8.0  268131  2441   344  1981          1    8     4  ...      1   \n",
       "2    1   16  7.0  167581   754   143  1995          1    3     2  ...      1   \n",
       "3    4   44  NaN  445071  5705   604  1980          1    3     4  ...      1   \n",
       "4    4   43  6.0  436161  5645   592  1958          1    3     4  ...      4   \n",
       "\n",
       "   LN2_3  LN2_4  LN2_RIndLngBEOth  LN2_WIndLngBEOth   GN1  GN2  GN3  GN4  GN5  \n",
       "0      1      1               NaN               NaN  99.0   99   99   99   99  \n",
       "1      3      4           Bengali           Bengali   NaN    1    2    2    2  \n",
       "2      2      2             Hindi             Hindi   1.0    2    2    2    2  \n",
       "3      4      5             Tamil             Tamil   NaN    2    2   99   99  \n",
       "4      4      4         Malayalam         Malayalam   NaN    1    1    1    1  \n",
       "\n",
       "[5 rows x 421 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just kept 421 columns\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18255, 421)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a csv\n",
    "train.to_csv(\"train_421_cols.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking columns for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_421_cols.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the label into another variable, dropping from main dataframe\n",
    "Y = train[\"is_female\"].values.astype(np.float32)\n",
    "X = train.drop(columns=[\"is_female\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling NAs and doing label encoding\n",
    "# Label encoding is simply converting each value in a column to a number (0 to num_classes).\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in X.columns:\n",
    "    if X.dtypes[col] == \"object\":\n",
    "        X[col] = X[col].fillna(\"NA\")\n",
    "    else:\n",
    "        X[col] = X[col].fillna(0)\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# telling pandas that all the variables are categorical\n",
    "for col in X.columns:\n",
    "    X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>DG4</th>\n",
       "      <th>...</th>\n",
       "      <th>LN2_2</th>\n",
       "      <th>LN2_3</th>\n",
       "      <th>LN2_4</th>\n",
       "      <th>LN2_RIndLngBEOth</th>\n",
       "      <th>LN2_WIndLngBEOth</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11369</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>424</td>\n",
       "      <td>482</td>\n",
       "      <td>252</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>831</td>\n",
       "      <td>831</td>\n",
       "      <td>410</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>310</td>\n",
       "      <td>166</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13476</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>664</td>\n",
       "      <td>564</td>\n",
       "      <td>300</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13406</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>587</td>\n",
       "      <td>111</td>\n",
       "      <td>76</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 420 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AA3 AA4 AA6  AA7 AA14 AA15 DG1 DG3 DG3A DG4  ... LN2_2 LN2_3 LN2_4  \\\n",
       "11369   1  10   2  424  482  252  62   2    3   4  ...     0     0     0   \n",
       "1250    2  17   1  831  831  410  63   2    3   5  ...     0     3     3   \n",
       "7527    1   8   0  301  310  166  53   2    3   0  ...     0     0     0   \n",
       "13476   2  14   2  664  564  300  69   2    3   4  ...     2     2     2   \n",
       "13406   0  12   3  587  111   76  58   2    3   2  ...     1     3     3   \n",
       "\n",
       "      LN2_RIndLngBEOth LN2_WIndLngBEOth GN1 GN2 GN3 GN4 GN5  \n",
       "11369               38               38   0   1   1   1   1  \n",
       "1250                33               32   1   2   2   0   0  \n",
       "7527                38               38   2   1   1   1   1  \n",
       "13476               14               14   3   2   2   2   2  \n",
       "13406               14               14   1   0   2   2   2  \n",
       "\n",
       "[5 rows x 420 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.20, random_state=3)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA3': 4,\n",
       " 'AA4': 22,\n",
       " 'AA6': 4,\n",
       " 'AA7': 1050,\n",
       " 'AA14': 907,\n",
       " 'AA15': 450,\n",
       " 'DG1': 79,\n",
       " 'DG3': 9,\n",
       " 'DG3A': 8,\n",
       " 'DG4': 12,\n",
       " 'DG6': 9,\n",
       " 'DG8a': 13,\n",
       " 'DG8b': 13,\n",
       " 'DG8c': 13,\n",
       " 'DG9a': 12,\n",
       " 'DG9b': 11,\n",
       " 'DG9c': 8,\n",
       " 'DG10b': 9,\n",
       " 'DG10c': 8,\n",
       " 'DG11b': 9,\n",
       " 'DL1': 12,\n",
       " 'DL2': 33,\n",
       " 'DL3': 3,\n",
       " 'DL5': 25,\n",
       " 'DL7': 3,\n",
       " 'DL8': 342,\n",
       " 'DL11': 15,\n",
       " 'DL14': 24,\n",
       " 'DL15': 4,\n",
       " 'DL24': 7,\n",
       " 'MT1': 13,\n",
       " 'MT1A': 8,\n",
       " 'MT3_1': 5,\n",
       " 'MT3_2': 6,\n",
       " 'MT3_3': 6,\n",
       " 'MT4_1': 3,\n",
       " 'MT4_2': 3,\n",
       " 'MT4_3': 3,\n",
       " 'MT4_4': 3,\n",
       " 'MT4_5': 3,\n",
       " 'MT4_6': 3,\n",
       " 'MT5': 8,\n",
       " 'MT6': 10,\n",
       " 'MT6A': 7,\n",
       " 'MT6B': 9,\n",
       " 'MT6C': 28,\n",
       " 'MT7': 3,\n",
       " 'MT11': 83,\n",
       " 'MT12_1': 5,\n",
       " 'MT12_2': 7,\n",
       " 'MT12_3': 6,\n",
       " 'MT12_4': 3,\n",
       " 'MT12_5': 3,\n",
       " 'MT12_7': 5,\n",
       " 'MT12_9': 3,\n",
       " 'MT12_11': 5,\n",
       " 'MT12_12': 3,\n",
       " 'MT12_13': 3,\n",
       " 'MT12_14': 3,\n",
       " 'MT14C_1': 5,\n",
       " 'MT14C_2': 5,\n",
       " 'MT14C_3': 5,\n",
       " 'MT14C_4': 5,\n",
       " 'MT15': 3,\n",
       " 'MT17_1': 7,\n",
       " 'MT17_2': 7,\n",
       " 'MT17_3': 7,\n",
       " 'MT17_4': 7,\n",
       " 'MT17_5': 7,\n",
       " 'MT17_6': 7,\n",
       " 'MT17_7': 7,\n",
       " 'MT17_8': 7,\n",
       " 'MT17_9': 7,\n",
       " 'MT17_10': 7,\n",
       " 'MT17_11': 7,\n",
       " 'MT17_12': 7,\n",
       " 'MT17_13': 7,\n",
       " 'MT18_1': 3,\n",
       " 'MT18_2': 3,\n",
       " 'MT18_3': 3,\n",
       " 'MT18_4': 3,\n",
       " 'MT18_5': 3,\n",
       " 'MT18_6': 3,\n",
       " 'MT18_96': 3,\n",
       " 'MT18_8': 3,\n",
       " 'FF2': 4,\n",
       " 'FF2A': 18,\n",
       " 'FF3': 27,\n",
       " 'FF4': 3,\n",
       " 'FF5': 4,\n",
       " 'FF6_1': 4,\n",
       " 'FF6_2': 4,\n",
       " 'FF6_3': 4,\n",
       " 'FF6_4': 4,\n",
       " 'FF6_5': 4,\n",
       " 'FF6_6': 4,\n",
       " 'FF6_7': 4,\n",
       " 'FF6_8': 4,\n",
       " 'FF6_9': 4,\n",
       " 'FF6_10': 4,\n",
       " 'FF7_1': 4,\n",
       " 'FF7_2': 4,\n",
       " 'FF7_4': 5,\n",
       " 'FF7_5': 4,\n",
       " 'FF7_6': 3,\n",
       " 'FF9': 7,\n",
       " 'FF10_1': 3,\n",
       " 'FF10_2': 3,\n",
       " 'FF10_3': 3,\n",
       " 'FF10_4': 3,\n",
       " 'FF10_5': 3,\n",
       " 'FF10_6': 3,\n",
       " 'FF10_96': 3,\n",
       " 'FF13': 8,\n",
       " 'FF14_1': 3,\n",
       " 'FF14_2': 3,\n",
       " 'FF14_3': 3,\n",
       " 'FF14_4': 3,\n",
       " 'FF14_5': 3,\n",
       " 'FF14_6': 3,\n",
       " 'FF14_7': 3,\n",
       " 'FF14_8': 3,\n",
       " 'FF14_9': 3,\n",
       " 'FF14_10': 3,\n",
       " 'FF14_11': 3,\n",
       " 'FF14_12': 3,\n",
       " 'FF14_13': 3,\n",
       " 'FF14_14': 3,\n",
       " 'FF14_15': 3,\n",
       " 'FF14_16': 3,\n",
       " 'FF14_17': 3,\n",
       " 'FF14_18': 3,\n",
       " 'FF14_19': 3,\n",
       " 'FF14_20': 3,\n",
       " 'FF14_21': 3,\n",
       " 'FF14_22': 3,\n",
       " 'FF14_23': 3,\n",
       " 'FF14_96': 3,\n",
       " 'FF16_1': 6,\n",
       " 'FF16_2': 6,\n",
       " 'FF19_1': 3,\n",
       " 'FF19_2': 3,\n",
       " 'FF19_3': 3,\n",
       " 'FF19_4': 3,\n",
       " 'FF19_5': 3,\n",
       " 'FF19_6': 3,\n",
       " 'FF19_7': 3,\n",
       " 'FF19_8': 3,\n",
       " 'MM3_1': 3,\n",
       " 'MM3_2': 3,\n",
       " 'MM3_3': 3,\n",
       " 'MM3_4': 3,\n",
       " 'MM3_5': 3,\n",
       " 'MM3_6': 3,\n",
       " 'MM3_7': 3,\n",
       " 'MM3_8': 3,\n",
       " 'MM3_9': 3,\n",
       " 'MM3_10': 3,\n",
       " 'MM3_11': 3,\n",
       " 'MM3_12': 3,\n",
       " 'MM3_13': 3,\n",
       " 'MM3_14': 3,\n",
       " 'IFI14_1': 7,\n",
       " 'IFI14_2': 7,\n",
       " 'IFI14_3': 7,\n",
       " 'IFI14_4': 7,\n",
       " 'IFI14_5': 7,\n",
       " 'IFI14_6': 7,\n",
       " 'IFI14_7': 7,\n",
       " 'IFI15_1': 7,\n",
       " 'IFI15_2': 7,\n",
       " 'IFI15_3': 7,\n",
       " 'IFI15_4': 7,\n",
       " 'IFI15_5': 7,\n",
       " 'IFI15_6': 7,\n",
       " 'IFI15_7': 7,\n",
       " 'IFI16_1': 11,\n",
       " 'IFI16_2': 11,\n",
       " 'IFI17_1': 7,\n",
       " 'IFI17_2': 7,\n",
       " 'IFI18': 9,\n",
       " 'IFI24': 12,\n",
       " 'FL1': 4,\n",
       " 'FL2': 5,\n",
       " 'FL3': 10,\n",
       " 'FL4': 19,\n",
       " 'FL7_1': 3,\n",
       " 'FL7_2': 3,\n",
       " 'FL7_3': 3,\n",
       " 'FL7_4': 3,\n",
       " 'FL7_5': 3,\n",
       " 'FL7_6': 3,\n",
       " 'FL8_1': 5,\n",
       " 'FL8_2': 5,\n",
       " 'FL8_3': 5,\n",
       " 'FL8_4': 5,\n",
       " 'FL8_5': 5,\n",
       " 'FL8_6': 5,\n",
       " 'FL8_7': 5,\n",
       " 'FL9A': 12,\n",
       " 'FL9B': 13,\n",
       " 'FL9C': 13,\n",
       " 'FL10': 13,\n",
       " 'FL11': 5,\n",
       " 'FL12': 3,\n",
       " 'FL14': 3,\n",
       " 'FL15': 4,\n",
       " 'FL16': 3,\n",
       " 'FL17': 3,\n",
       " 'FL18': 3,\n",
       " 'FB2': 3,\n",
       " 'FB13': 25,\n",
       " 'FB18': 5,\n",
       " 'FB19': 11,\n",
       " 'FB19B_1': 4,\n",
       " 'FB19B_2': 4,\n",
       " 'FB19B_3': 4,\n",
       " 'FB19B_4': 4,\n",
       " 'FB19B_5': 4,\n",
       " 'FB19B_96': 4,\n",
       " 'FB20': 16,\n",
       " 'FB24': 17,\n",
       " 'FB26_1': 3,\n",
       " 'FB26_2': 3,\n",
       " 'FB26_3': 3,\n",
       " 'FB26_4': 3,\n",
       " 'FB26_5': 3,\n",
       " 'FB26_6': 3,\n",
       " 'FB26_7': 3,\n",
       " 'FB26_8': 3,\n",
       " 'FB26_9': 3,\n",
       " 'FB26_10': 3,\n",
       " 'FB26_11': 3,\n",
       " 'FB26_96': 3,\n",
       " 'FB26_99': 3,\n",
       " 'LN1A': 4,\n",
       " 'LN1B': 4,\n",
       " 'LN2_1': 5,\n",
       " 'LN2_2': 5,\n",
       " 'LN2_3': 5,\n",
       " 'LN2_4': 5,\n",
       " 'LN2_RIndLngBEOth': 58,\n",
       " 'LN2_WIndLngBEOth': 59,\n",
       " 'GN1': 7,\n",
       " 'GN2': 6,\n",
       " 'GN3': 6,\n",
       " 'GN4': 6,\n",
       " 'GN5': 6}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variables with two values are fine \n",
    "# number of values for variables with more than 2 values\n",
    "emb_c = {n: len(col.cat.categories) for n,col in X.items() if len(col.cat.categories) > 2}\n",
    "emb_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 2),\n",
       " (22, 11),\n",
       " (4, 2),\n",
       " (1050, 20),\n",
       " (907, 20),\n",
       " (450, 20),\n",
       " (79, 20),\n",
       " (9, 5),\n",
       " (8, 4),\n",
       " (12, 6),\n",
       " (9, 5),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (12, 6),\n",
       " (11, 6),\n",
       " (8, 4),\n",
       " (9, 5),\n",
       " (8, 4),\n",
       " (9, 5),\n",
       " (12, 6),\n",
       " (33, 17),\n",
       " (3, 2),\n",
       " (25, 13),\n",
       " (3, 2),\n",
       " (342, 20),\n",
       " (15, 8),\n",
       " (24, 12),\n",
       " (4, 2),\n",
       " (7, 4),\n",
       " (13, 7),\n",
       " (8, 4),\n",
       " (5, 3),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (8, 4),\n",
       " (10, 5),\n",
       " (7, 4),\n",
       " (9, 5),\n",
       " (28, 14),\n",
       " (3, 2),\n",
       " (83, 20),\n",
       " (5, 3),\n",
       " (7, 4),\n",
       " (6, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (18, 9),\n",
       " (27, 14),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (5, 3),\n",
       " (4, 2),\n",
       " (3, 2),\n",
       " (7, 4),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (8, 4),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (11, 6),\n",
       " (11, 6),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (9, 5),\n",
       " (12, 6),\n",
       " (4, 2),\n",
       " (5, 3),\n",
       " (10, 5),\n",
       " (19, 10),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (12, 6),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (25, 13),\n",
       " (5, 3),\n",
       " (11, 6),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (16, 8),\n",
       " (17, 9),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (58, 20),\n",
       " (59, 20),\n",
       " (7, 4),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (6, 3)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of the category, size of the embedding\n",
    "# 30 and (c+1)//2) are arbitrary (we should play with these numbers)\n",
    "emb_szs = [(c, min(20, (c+1)//2)) for _,c in emb_c.items()]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AA3', 'AA4', 'AA6', 'AA7', 'AA14', 'AA15', 'DG1', 'DG3', 'DG3A', 'DG4', 'DG6', 'DG8a', 'DG8b', 'DG8c', 'DG9a', 'DG9b', 'DG9c', 'DG10b', 'DG10c', 'DG11b', 'DL1', 'DL2', 'DL3', 'DL5', 'DL7', 'DL8', 'DL11', 'DL14', 'DL15', 'DL24', 'MT1', 'MT1A', 'MT3_1', 'MT3_2', 'MT3_3', 'MT4_1', 'MT4_2', 'MT4_3', 'MT4_4', 'MT4_5', 'MT4_6', 'MT5', 'MT6', 'MT6A', 'MT6B', 'MT6C', 'MT7', 'MT11', 'MT12_1', 'MT12_2', 'MT12_3', 'MT12_4', 'MT12_5', 'MT12_7', 'MT12_9', 'MT12_11', 'MT12_12', 'MT12_13', 'MT12_14', 'MT14C_1', 'MT14C_2', 'MT14C_3', 'MT14C_4', 'MT15', 'MT17_1', 'MT17_2', 'MT17_3', 'MT17_4', 'MT17_5', 'MT17_6', 'MT17_7', 'MT17_8', 'MT17_9', 'MT17_10', 'MT17_11', 'MT17_12', 'MT17_13', 'MT18_1', 'MT18_2', 'MT18_3', 'MT18_4', 'MT18_5', 'MT18_6', 'MT18_96', 'MT18_8', 'FF2', 'FF2A', 'FF3', 'FF4', 'FF5', 'FF6_1', 'FF6_2', 'FF6_3', 'FF6_4', 'FF6_5', 'FF6_6', 'FF6_7', 'FF6_8', 'FF6_9', 'FF6_10', 'FF7_1', 'FF7_2', 'FF7_4', 'FF7_5', 'FF7_6', 'FF9', 'FF10_1', 'FF10_2', 'FF10_3', 'FF10_4', 'FF10_5', 'FF10_6', 'FF10_96', 'FF13', 'FF14_1', 'FF14_2', 'FF14_3', 'FF14_4', 'FF14_5', 'FF14_6', 'FF14_7', 'FF14_8', 'FF14_9', 'FF14_10', 'FF14_11', 'FF14_12', 'FF14_13', 'FF14_14', 'FF14_15', 'FF14_16', 'FF14_17', 'FF14_18', 'FF14_19', 'FF14_20', 'FF14_21', 'FF14_22', 'FF14_23', 'FF14_96', 'FF16_1', 'FF16_2', 'FF19_1', 'FF19_2', 'FF19_3', 'FF19_4', 'FF19_5', 'FF19_6', 'FF19_7', 'FF19_8', 'MM3_1', 'MM3_2', 'MM3_3', 'MM3_4', 'MM3_5', 'MM3_6', 'MM3_7', 'MM3_8', 'MM3_9', 'MM3_10', 'MM3_11', 'MM3_12', 'MM3_13', 'MM3_14', 'IFI14_1', 'IFI14_2', 'IFI14_3', 'IFI14_4', 'IFI14_5', 'IFI14_6', 'IFI14_7', 'IFI15_1', 'IFI15_2', 'IFI15_3', 'IFI15_4', 'IFI15_5', 'IFI15_6', 'IFI15_7', 'IFI16_1', 'IFI16_2', 'IFI17_1', 'IFI17_2', 'IFI18', 'IFI24', 'FL1', 'FL2', 'FL3', 'FL4', 'FL7_1', 'FL7_2', 'FL7_3', 'FL7_4', 'FL7_5', 'FL7_6', 'FL8_1', 'FL8_2', 'FL8_3', 'FL8_4', 'FL8_5', 'FL8_6', 'FL8_7', 'FL9A', 'FL9B', 'FL9C', 'FL10', 'FL11', 'FL12', 'FL14', 'FL15', 'FL16', 'FL17', 'FL18', 'FB2', 'FB13', 'FB18', 'FB19', 'FB19B_1', 'FB19B_2', 'FB19B_3', 'FB19B_4', 'FB19B_5', 'FB19B_96', 'FB20', 'FB24', 'FB26_1', 'FB26_2', 'FB26_3', 'FB26_4', 'FB26_5', 'FB26_6', 'FB26_7', 'FB26_8', 'FB26_9', 'FB26_10', 'FB26_11', 'FB26_96', 'FB26_99', 'LN1A', 'LN1B', 'LN2_1', 'LN2_2', 'LN2_3', 'LN2_4', 'LN2_RIndLngBEOth', 'LN2_WIndLngBEOth', 'GN1', 'GN2', 'GN3', 'GN4', 'GN5'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_cols = emb_c.keys()\n",
    "emb_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Dataset is a custom class to conveniently interact with a set observations. Designing this Dataset class is up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all variables are categorical, but some of them has just two values \n",
    "# emb_c are the variables we plan to embed\n",
    "class WiDSDataset(Dataset):\n",
    "    def __init__(self, X, Y, emb_cols):\n",
    "        X = X.copy()\n",
    "        # splitting categorical columns and numerical columns\n",
    "        self.X1 = X.loc[:,emb_cols].copy().values.astype(np.int64)\n",
    "        self.X2 = X.drop(columns=emb_cols).copy().values.astype(np.float32)\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X1[idx], self.X2[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = WiDSDataset(X_train, y_train, emb_cols)\n",
    "valid_ds = WiDSDataset(X_val, y_val, emb_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   4,   3, 200, 229, 129,  72,   0,   3,   5,   2,   5,   3,\n",
       "          1,   3,   0,   0,   3,   0,   3,   5,   0,   0,   0,   1, 136,\n",
       "          0,   8,   3,   0,   1,   7,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   1,   2,   0,   0,   1,   3,\n",
       "          1,   3,   2,   1,   2,   3,   2,   2,   2,   0,   0,   1,   0,\n",
       "          0,   4,   1,   2,   2,   2,   2,   2,   2,   1,   1,   1,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   4,   4,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   0,   2,   2,   6,   6,   6,   6,   6,   6,\n",
       "          1,   6,   6,   6,   6,   6,   6,   6,   0,   1,   0,   8,   0,\n",
       "          3,   0,   0,   7,   1,   1,   1,   1,   1,   1,   1,   3,   2,\n",
       "          1,   1,   3,   2,  10,   0,   0,   0,   1,   0,   0,   0,   1,\n",
       "          0,   0,   1,  24,   4,   9,   3,   2,   2,   2,   2,   2,  15,\n",
       "          0,   2,   2,   2,   2,   1,   1,   1,   1,   2,   2,   1,   2,\n",
       "          2,   1,   1,   0,   0,   3,   3,  14,  14,   0,   2,   2,   3,\n",
       "          2]),\n",
       " array([0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.], dtype=float32),\n",
       " 0.0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from fast.ai\n",
    "class MixedInputModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont):\n",
    "        super().__init__()\n",
    "        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embs) \n",
    "        self.n_emb, self.n_cont = n_emb, n_cont\n",
    "        self.lin1 = nn.Linear(self.n_emb + self.n_cont, 100)\n",
    "        self.lin2 = nn.Linear(100, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.emb_drop = nn.Dropout(0.5)\n",
    "        self.drops = nn.Dropout(0.2)\n",
    "        \n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x2 = self.bn1(x_cont)\n",
    "        x = torch.cat([x, x2], 1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixedInputModel(emb_szs, 172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 248]) torch.Size([5, 172]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "x1, x2, y = next(iter(train_dl))\n",
    "print(x1.shape, x2.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 3, 2, 0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2628, -0.9250],\n",
       "        [-2.2628, -0.9250],\n",
       "        [ 2.1789,  0.3396],\n",
       "        [ 0.6629,  1.0533],\n",
       "        [-0.1358, -0.4572]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[0](x1[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3648],\n",
       "        [ 0.3102],\n",
       "        [-0.3776],\n",
       "        [-0.0326],\n",
       "        [ 0.0477]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.unsqueeze(1)\n",
    "out = model(x1, x2)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (out > 0.0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred == y).float().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7377, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy_with_logits(out, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optim, train_dl=train_dl, verbose=False):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for x1, x2, y in train_dl:\n",
    "        batch = y.shape[0]\n",
    "        y = y.unsqueeze(1)  \n",
    "        out = model(x1, x2)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, y)   \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "        if verbose: print(sum_loss/total)\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    for x1, x2, y in valid_dl:\n",
    "        batch = y.shape[0]\n",
    "        y = y.unsqueeze(1)\n",
    "        out = model(x1, x2)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, y)\n",
    "        sum_loss += batch*(loss.item())\n",
    "        total += batch\n",
    "        pred = (out > 0).float()\n",
    "        correct += (pred == y).float().sum().item()\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def train_loop(model, epochs, lr=0.01, wd=0.0):\n",
    "    optim = get_optimizer(model, lr = lr, wd = wd)\n",
    "    for i in range(epochs): \n",
    "        loss = train_model(model, optim, train_dl)\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        print(\"train loss %.3f val loss %.3f and accuracy %.3f\" % (\n",
    "            loss, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixedInputModel(emb_szs, 172) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the higest learning rate that doesn't cycle \n",
    "#optim = get_optimizer(model, lr = 0.1, wd = 0.0)\n",
    "#train_model(model, optim, train_dl, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.419 val loss 0.290 and accuracy 0.880\n",
      "train loss 0.283 val loss 0.244 and accuracy 0.898\n",
      "train loss 0.253 val loss 0.257 and accuracy 0.890\n",
      "train loss 0.235 val loss 0.256 and accuracy 0.902\n",
      "train loss 0.221 val loss 0.243 and accuracy 0.906\n",
      "train loss 0.213 val loss 0.252 and accuracy 0.906\n",
      "train loss 0.205 val loss 0.256 and accuracy 0.907\n",
      "train loss 0.202 val loss 0.264 and accuracy 0.899\n",
      "train loss 0.194 val loss 0.264 and accuracy 0.896\n",
      "train loss 0.190 val loss 0.261 and accuracy 0.902\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, epochs=10, lr=0.05, wd=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate (LR) range test\n",
    "The [learning rate range test](https://arxiv.org/abs/1506.01186) is a way to estimate minimum and maximum boundary values for learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))\n",
    "\n",
    "def LR_range_finder(model, train_dl, lr_low=1e-5, lr_high=1, epochs=2):\n",
    "    losses = []\n",
    "    p = \"model_tmp.pth\"\n",
    "    save_model(model, str(p))\n",
    "    iterations = epochs * len(train_dl)\n",
    "    delta = (lr_high - lr_low)/iterations\n",
    "    lrs = [lr_low + i*delta for i in range(iterations)]\n",
    "    model.train()\n",
    "    ind = 0\n",
    "    for i in range(epochs):\n",
    "        for j, (x1, x2, y) in enumerate(train_dl):\n",
    "            # changing learning rate at each iteration\n",
    "            optim = get_optimizer(model, lr=lrs[ind])\n",
    "            batch = y.shape[0]\n",
    "            y = y.unsqueeze(1)  \n",
    "            out = model(x1, x2)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y)   \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            losses.append(loss.item())\n",
    "            ind +=1\n",
    "            \n",
    "    load_model(model, str(p))\n",
    "    return lrs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)\n",
    "model = MixedInputModel(emb_szs, 172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_low, lr_high and batch_size are important so that the plot gives\n",
    "# useful information\n",
    "lrs, losses = LR_range_finder(model, train_dl, lr_low=1e-4, lr_high=0.1, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lrs, losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick the lower boundary as the value of the learning rate when the loss starts to decrease. Pick the upper learning rate when the loss slows, becomes ragged or increases. From this graph I would try $base\\_lr=1e-4$ and $max\\_lr=0.04$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_segment(start_lr, end_lr, iterations):\n",
    "    i = np.arange(iterations)\n",
    "    c_i = 1 + np.cos(i*np.pi/iterations)\n",
    "    return end_lr + (start_lr - end_lr)/2 *c_i\n",
    "\n",
    "def get_cosine_triangular_lr(max_lr, iterations):\n",
    "    min_start, min_end = max_lr/25, max_lr/(25*1e4)\n",
    "    iter1 = int(0.3*iterations)\n",
    "    iter2 = iterations - iter1\n",
    "    segs = [cosine_segment(min_start, max_lr, iter1), cosine_segment(max_lr, min_end, iter2)]\n",
    "    return np.concatenate(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 2000\n",
    "lr = get_cosine_triangular_lr(0.001, N)\n",
    "plt.plot(list(range(N)), lr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_triangular_policy(model, train_dl, valid_dl, max_lr=0.01, epochs=4):\n",
    "    idx = 0\n",
    "    iterations = epochs*len(train_dl)\n",
    "    lrs = get_cosine_triangular_lr(max_lr, iterations)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for i, (x1, x2, y) in enumerate(train_dl):\n",
    "            optim = get_optimizer(model, lr = lrs[idx], wd = 0.00001)\n",
    "            batch = y.shape[0]\n",
    "            y = y.unsqueeze(1)  \n",
    "            out = model(x1, x2)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y) \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            idx += 1\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        print(\"train loss\", sum_loss/total)\n",
    "        val_loss(model, valid_dl)\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a new model\n",
    "model = MixedInputModel(emb_szs, 172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.45023822681572756\n",
      "val loss 0.393 and accuracy 0.856\n",
      "train loss 0.3728232829416004\n",
      "val loss 0.466 and accuracy 0.835\n",
      "train loss 0.34141300615791553\n",
      "val loss 0.296 and accuracy 0.866\n",
      "train loss 0.31351019777571854\n",
      "val loss 0.273 and accuracy 0.878\n",
      "train loss 0.29257091015814035\n",
      "val loss 0.256 and accuracy 0.890\n",
      "train loss 0.27056312952032485\n",
      "val loss 0.247 and accuracy 0.892\n",
      "train loss 0.25537933604304547\n",
      "val loss 0.246 and accuracy 0.894\n",
      "train loss 0.2386973602898772\n",
      "val loss 0.234 and accuracy 0.899\n",
      "train loss 0.23197157010007513\n",
      "val loss 0.229 and accuracy 0.907\n",
      "train loss 0.22505255803461763\n",
      "val loss 0.228 and accuracy 0.907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22505255803461763"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triangular_policy(model, train_dl, valid_dl, max_lr=0.04, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go back and add m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
